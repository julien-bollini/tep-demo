import pandas as pd
import numpy as np
from pathlib import Path
from src.config import (
    PARQUET_DATA_PATH,
    PROCESSED_DATA_PATH,
    DEFAULT_N_SIMULATIONS,
    MERGED_FILE_PATH,
    N_SIMU_FILE_PATH
)

class DataLoader:
    """Charge et pr√©pare les donn√©es pour l'entra√Ænement"""

    def __init__(self, data_path=None):
        self.data_path = Path(data_path) if data_path else PARQUET_DATA_PATH

    def load_data(self, file_path=MERGED_FILE_PATH, n_simulations=DEFAULT_N_SIMULATIONS):
        """
        Charge les donn√©es et applique un sous-√©chantillonnage si demand√©.
        """
        # Utilise le chemin pass√© en argument ou celui par d√©faut
        path = Path(file_path) if file_path else self.data_path

        if path is None or not path.exists():
            raise FileNotFoundError(f"‚ùå Chemin invalide : {path}")

        print(f"üìñ Chargement de : {path.name}...")
        df = pd.read_parquet(path)

        # Si n_simulations est pr√©cis√©, on r√©duit le dataset
        if n_simulations is not None:
            df = self._subsample_by_run(df, n_simulations)

        # Save the final merged file
        df.to_parquet(N_SIMU_FILE_PATH, engine="pyarrow", index=False)
        print(f"‚úÖ Merging completed and saved to: {N_SIMU_FILE_PATH.name}")

        # S√©paration classique X (features) et y (target)
        # On exclut les colonnes de m√©tadonn√©es pour l'entra√Ænement
        metadata_cols = ['faultNumber', 'simulationRun', 'sample']
        X = df.drop(columns=metadata_cols)
        y = df['faultNumber']

        return X, y

    def _subsample_by_run(self, df, n_simulations=DEFAULT_N_SIMULATIONS):
        """
        Logique interne pour filtrer par simulationRun.
        """
        print(f"üìâ R√©duction √† {n_simulations} simulations par type de d√©faut...")

        # Ajout de include_groups=False pour √©viter le Warning
        return (
            df.groupby('faultNumber')
            .apply(
                lambda x: x[x['simulationRun'].isin(x['simulationRun'].unique()[:n_simulations])],
                include_groups=False
            )
            .reset_index(level=0) # On remet 'faultNumber' qui a √©t√© d√©plac√© dans l'index
            .reset_index(drop=True)
        )

    def save_test_set(self, df_test):
        """Sauvegarde le test set pour √©valuation ult√©rieure"""
        PROCESSED_DATA_PATH.mkdir(parents=True, exist_ok=True)
        output_path = PROCESSED_DATA_PATH / "test_set.parquet"
        df_test.to_parquet(output_path, index=False)
        print(f"‚úîÔ∏è Test set saved: {output_path}")
